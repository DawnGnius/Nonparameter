---
title: "HW 17"
author: "Liu Huihang"
date: "December 6, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

The objective in this exercise is to estimate the production function for Chinaâ€™s nongovernmental businesses for the Year 2003. 
The data include $2052$ valid observations on $7$ variables: *Output*, *capital*, *Labor*, *Province*, *Ownership*, *Industry*, and *List*, where the first three variables are self-defined, and the other variables are categorical variables (for example, $List = 1$ if a business is a listed company, $0$ otherwise). 

Please use the dataset (*Business03.txt*) to answer the following questions:

(1) Run a multiple linear regression (MLR) model by regressing $ln(Output)$ on a constant term, $ln(Capital)$ and $ln(Labor)$:
\begin{equation}
Y = m(X_1, X_2) + u
\end{equation}
where $Y=ln(Output)$, $X_1=ln(Capital)$, and $X_2=ln(Labor)$, and $u$ is the disturbance term. 
Report the regression results in the standard format. 
That is, you need to report the regression model, the $t$-values, or the $p$-values or the corresponding standard errors for the coefficients in the model, $R^2$, $\bar{R}^2$ (Adjusted $R^2$), and the $F$ test statistic or its corresponding $p$-value. 

(2) Run a nonparametric regression model by regressing $ln(Output)$ on $ln(Labor)$ and $ln(Labor)$ by using the local constant procedure
\begin{equation}
Y = m(X_1, X_2) + u
\end{equation}
Denote the regression estimates by $\hat{m}_{lc}(x_1,x_2).$. Calculate the $R^2$ based upon the formula
\begin{equation}
R^2=\frac{[\sum_{i=1}^n(Y_i-\bar{Y})(\hat{Y}_i-\bar{\hat{Y}}]^2}{\sum_{i=1}^n(Y_i-\bar{Y})^2\sum_{i=1}^n(\hat{Y}_i-\bar{\hat{Y}})^2},
\end{equation}
which is the squre of the sample correlation between $Y_i$ and $\hat{Y}_i$, where $\hat{Y}_i=\hat{m}_{lc}(X_{1i},X_{2i})$ is the insample predict value for $Y_i$,
$\bar{Y}=\frac1n\sum_{i=1}^nY_i$, and $\bar{\hat{Y}}=\frac1n\sum_{i=1}^n\hat{Y}_i$. 
Plot $\hat{Y}$ against $X_1$ and $X_2$ in a three-dimensional diagrm.
Does the diagram lend any support to the MLR model in part (1)?

(3) Repeat part (2) by using the local linear procedure. 

(4) Test the correct specification of the model in part (1) using **np package**.

## Solution

1. Multiple linear regression (MLR)
```{r}
# load data
dat <- read.table('./Business03.txt')

# logarithm
y <- log(as.numeric(dat[-1, 1]))
x1 <- log(as.numeric(dat[-1, 3]))
x2 <- log(as.numeric(dat[-1, 2]))

# regressing ln(Output) on a constant term, ln(Capital) and ln(Labor)
fit.lm <- lm(y ~ x1 + x2, x=TRUE, y=TRUE)

# Report the regression results in the standard format.
summary(fit.lm)
```

The results are show above, returned by innner function *summary*. 


2. Nonparametric regression (NR)
Local constant procedure can be implemented by function *loess* in *stats* package. 
*loess* fit a polynomial surface determined by one or more numerical predictors, using local fitting. 
Setting $degree = p$, $p$ degree of the polynomials will be used. 

> Note that $degree = 0$, local constant fitting, is allowed in this implementation but not documented in the reference. It seems very little tested, so use with caution. 

Also, function *npreg* in package *np* provide an alternative choose to use the local constant regression. But it takes long time to converge to a optimal bandwidth. 

```{r, message=FALSE}
library(np)
bw <- npregbw(formula = y~x1+x2)  # npregbw, bandwidth selection
model <- npreg(bw)                # regression method

# using npplot to draw a fixed 3d figure
npplot(bws=bw, view="fixed", theta=30, phi=0)
```

The figure shows that the relation between $y$ and $x$s may not be linear. 
Further, when we fix $x_1$ and change the value of $x_2$, we will find $y$ hardly change with $x_2$, which means that $x_2$ maybe not do contribution to $y$. 

3. Local linear procedure (LL)
The local linear nonparametric method can be used by set parameter *regtype* to *"ll"* when we use *npreg*

```{r}
# # regression using npreg
# # model.np <- npreg(y ~  x1 + x2, regtype = "ll", bwmethod = "cv.aic")

bw <- npregbw(formula = y~x1+x2, regtype="ll")  # npregbw, bandwidth selection
npplot(bws=bw, view="fixed", theta=30, phi=0)

model.np <- npreg(bws=bw)
summary(model.np)

x1.seq <- seq(0, 8, length.out=20)
x2.seq <- seq(0, 8, length.out=20)
X.eval <- expand.grid(x1=x1.seq, x2=x2.seq)
# X.eval <- expand.grid(x1=x1, x2=x2)           # take a long time
pre.np <- fitted(npreg(exdat=X.eval, eydat=rep(1, nrow(X.eval)), bws=bw))

# draw scatter plot and surface plot
library(plot3D)
tmp <- plot3D::mesh(x1.seq, x2.seq)
xx <- tmp$x; yy <- tmp$y; zz <- matrix(pre.np, nrow=nrow(xx), byrow=TRUE)
surf3D(x=xx, y=yy, z=zz, xlab="ln(Capital)", ylab="ln(Labor)", zlab="ln(Output)", main="npreg", bty = "f", colkey=FALSE, colvar=matrix(rep(1, length(zz)), nrow(zz)), border = "black", theta=30, phi=30, plot = FALSE)
scatter3D(x=x1, y=x2, z=y, col="black", bty = "b", add=TRUE, plot=TRUE)
```

4. Test

We can use *npcmstest* in *np* to test the model in (1).
It uses boostrap to get "Jn" statitstics and report the p-value.

```{r}
npcmstest(model=fit.lm, xdat=data.frame(x1,x2), ydat=y)
```

The p-value shows that the model is wrong. 