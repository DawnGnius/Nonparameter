---
title: "Rodeo"
author: "Liu Huihang"
date: "11/26/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## One-Dimensional Example

We are going to estimate the density of simulated one-dim data using classical DE methods and proposed method.

### Basic KDE methods
```{r}
# data preparation
set.seed(111)
n <- 200
Num.Cmp <- 8
pro <- rep(1/8, Num.Cmp)
multi <- sample(1:Num.Cmp, n, replace = T, prob=pro)
mu <- 3 * ((2/3)^(1:Num.Cmp) - 1)
sigma <- (2/3)^(1:Num.Cmp)
x <- NULL
for (ii in 1:Num.Cmp) {
  com_txt <- paste("com", ii, " <- rnorm(length(which(multi==", ii, ")), mean=", mu[ii], ", sd=", sigma[ii], ")",sep="")
  eval(parse(text=com_txt))
  com_txt <- paste("x <- c(x, com", ii, ")", sep="")
  eval(parse(text=com_txt))
}

# true density function, y is h, and z is v.
y <- seq(-3, 1, 0.01)
z <- rep(0, length(y))
for (ii in 1:Num.Cmp) {
  z <- z + pro[ii] * dnorm(y, mean=mu[ii], sd=sigma[ii])
}
```

### Rodeo algorithm
```{r}
# Rodeo local for 1-dim
rodeo.local.bw1 <- function(xx, x, h.init=1.3/log(log(n)), beta=0.9, cn=log(n)/n){
  # bandwidth selection
  # para: xx        target point at which we want to estimate f(x)
  # para: x         samples
  # para: beta      learning rate
  # value: h.init   bandwidth
  h1 <- h.init
  while(TRUE){
    Z.i <- ((xx - x)^2 - h1^2) * exp(- (xx - x)^2 / h1^2 / 2) / h1^4 / sqrt(2*pi)
    Z <- mean(Z.i) 
    s <- var(Z.i)
    lam <- sqrt(2*s*log(n*cn)) / 10
    if (abs(Z) > lam) {
      h1 <- h1 * beta
    } else {
      return(h1)
    }
  }
}

rodeo.local1 <- function(t, x){
  # estimate target points t
  # para: t   target points, a vector
  # para: x   data points, a vector
  h <- unlist(base::lapply(X=t, FUN=rodeo.local.bw1, x=x))
  K <- stats::dnorm
  f.hat <- unlist(base::lapply(X=1:length(t), FUN=function(ii) mean(K((t[ii] - x) / h[ii]))/ h[ii]))
  return(f.hat)
}

# plot h and density
t <- seq(-3, 1, 0.01)
h <- unlist(base::lapply(X=t, FUN=rodeo.local.bw1, x=x))
plot(t, h, "l", main="Bandwidth of Rodeo", xlab="x", ylab="h")
fit.rodeo <- rodeo.local1(t=t, x=x)
plot(t, fit.rodeo, "l", lty=2, ylim=c(0,2.5), xlim=c(-3, 1), main="Rodeo", xlab="x", ylab="Density")
lines(y, z, lty=1, lwd=2)
legend("topright", legend=c("True Density", "Rodeo"), col=1, lty=c(1, 2), lwd=c(2, 1))
```

```{r}
# plot result
par(mfrow=c(1, 2))

# plot histogram
hist(x, breaks=50, freq=FALSE, ylim=c(0,2.5), xlim=c(-3, 1))
lines(y, z, lty=1, lwd=1)
text(x=0, y=1, paste("Breaks=", 50))

# built-in kernel density estimator: density
library(MASS)   # unbiased cross-validation to select the bandwidth of a Gaussian kernel density estimator
h.opt <- MASS::ucv(x, nb=1000, lower=0.1)
cat("The optimal bandwidth given by unbiased cv is: ", h.opt)
fit.density <- stats::density(x, kernel="gaussian", bw=h.opt)
plot(fit.density, "l", lty=2, main="KDE with U-CV", ylim=c(0,2.5), xlim=c(-3, 1), xlab="x")
lines(y, z, lty=1, lwd=1)
text(x=-0.5, y=1, paste("Bandwidth=", round(h.opt,4)))
```

We plot them into one figure as following
```{r, echo=FALSE}
# plot result
par(mfrow=c(2, 2), pty="m", cex.axis=1, cex.lab=1, cex.main=1)

# plot histogram
hist(x, breaks=50, freq=FALSE, ylim=c(0,2.5), xlim=c(-3, 1))
lines(y, z, lty=2)
text(x=0, y=1, paste("Breaks=", 50))

# built-in kernel density estimator: density
library(MASS)   # unbiased cross-validation to select the bandwidth of a Gaussian kernel density estimator
h.opt <- MASS::ucv(x, nb=1000, lower=0.1)
fit.density <- stats::density(x, kernel="gaussian", bw=h.opt)
plot(fit.density, main="KDE with U-CV", ylim=c(0,2.5), xlim=c(-3, 1), xlab="x")
lines(y, z, lty=2)
text(x=-0.5, y=1, paste("Bandwidth=", round(h.opt,4)))

# Rodeo density
t <- seq(-3, 1, 0.01)
h <- unlist(base::lapply(X=t, FUN=rodeo.local.bw1, x=x))
fit.rodeo <- rodeo.local1(t=t, x=x)
plot(t, fit.rodeo, "l", lty=1, ylim=c(0,2.5), xlim=c(-3, 1), main="Rodeo", xlab="x", ylab="Density")
lines(y, z, lty=2, lwd=1.5)
legend("topright", legend=c("True Density", "Rodeo"), col=1, lty=c(1, 2), lwd=c(2, 1))

# Rodeo h
plot(t, h, "l", main="Bandwidth of Rodeo", xlab="x", ylab="h")
```

## Two-Dimensional Example

We evaluate a simulated dataset and a real dataset. 
The density rodeoâ€™s performance is compared with the built-in method *KDE2d* from the  *MASS* package in R. 

### Mixture of Beta distributions, with the uniform distribution for an irrelevant dimension

Data
```{r}
# data preparation
set.seed(13245)

n <- 6000
Num.Cmp <- 2
pro <- c(2/3, 1/3)
multi <- sample(1:Num.Cmp, n, replace = T, prob=pro)
shape1 <- c(1, 10)
shape2 <- c(2, 10)
x1 <- NULL
for (ii in 1:Num.Cmp) {
  com_txt <- paste("com", ii, " <- rbeta(length(which(multi==", ii, ")), shape1=", shape1[ii], ", shape2=", shape2[ii], ")",sep="")
  eval(parse(text=com_txt))
  com_txt <- paste("x1 <- c(x1, com", ii, ")", sep="")
  eval(parse(text=com_txt))
}
x2 <- runif(n, 0, 1)
samples <- cbind(x1, x2)

p <- dim(samples)[2]
n <- dim(samples)[1]

# true density of first dimension
pro <- c(2/3, 1/3)
shape1 <- c(1, 10)
shape2 <- c(2, 10)
y <- seq(0, 1, 0.01)
z <- rep(0, length(y))
for (ii in 1:2) {
  z <- z + pro[ii] * dbeta(y, shape1[ii], shape2[ii])
}
```

KDE2D esitmation
```{r, warning=FALSE, message=FALSE}
# KDE2D esitmation
library(MASS)
fit.kde2d <- MASS::kde2d(x1, x2)

# draw figures
library(plot3D)
xx <- as.matrix(fit.kde2d$x)
yy <- as.matrix(fit.kde2d$y)
zz <- as.matrix(fit.kde2d$z)

tmp <- plot3D::mesh(xx, yy)
xx <- tmp$x
yy <- tmp$y
surf3D(x=xx, y=yy, z=zz, xlab="relevant variable", ylab="irrelevant variable", zlab="Density", main="KDE2d", bty = "f", colkey=FALSE, colvar=matrix(rep(1, length(zz)), nrow(zz)), border = "black", theta=0)
```

main function of rodeo in 2 dim
```{r, warning=FALSE, message=FALSE}
# Rodeo lacal multivariable version
library(stats)

# for 2-dim
rodeo.local.bw2 <- function(xx, x, h.init=1/log(log(n)), beta=0.95, cn=log(n)/n){
  # bandwidth selection
  # para: xx        target point at which we want to estimate f(x), 2 dim vector
  # para: x         samples, n*2 matrix
  # para: beta      learning rate
  # value: h.hat    bandwidth selected, a 2 dim vector
  h.hat <- rep(h.init, 2)
  A <- 1:p
  while(length(A) > 0){
    for (jj in A) {
      Z.i <- ((xx[jj] - x[, jj])^2 - h.hat[jj]^2) * exp(- (xx[1] - x[,1])^2 / h.hat[1]^2 / 2) * exp(- (xx[2] - x[,2])^2 / h.hat[2]^2 / 2) / h.hat[jj]^3 / h.hat[1] / h.hat[2] / 2 / pi
      Z <- mean(Z.i) 
      s <- var(Z.i)
      lam <- sqrt(2*s*log(n*cn)) / 30
      if (abs(Z) > lam) {
        h.hat[jj] <- h.hat[jj] * beta
      } else {
        A <- A[A != jj]
      }
    }
  }
  return(h.hat)
}

rodeo.local2 <- function(t, x){
  # estimate target points t
  # para: t   target points, a matrix, each row is a point
  # para: x   data points, a matrix, each row is a point
  h <- t(base::apply(X=t, MARGIN=1, FUN=rodeo.local.bw2, x=x))
  K <- stats::dnorm
  f.hat <- unlist(base::lapply(X=1:dim(t)[1], FUN=function(ii) mean(K((t[ii, 1] - x[, 1]) / h[ii, 1]) * K((t[ii, 2] - x[, 2]) / h[ii, 2])) / h[ii, 1] / h[ii, 2]))
  return(list(f.hat=f.hat, h.hat=h))
}
```

The following is complete Rodeo, unstable.

```{r, eval=FALSE}
# Rodeo lacal multivariable version
library(stats)
library(mvtnorm)   # for pmvnorm density of multivariate normal distribution
library(snowfall)  # for parallel loop

rodeo.local.bw <- function(xx, samples, h.init=0.6/log(log(n)), beta=0.95, cn=log(n)/n){
  # bandwidth selection
  # para: xx        target point at which we want to estimate f(x), p dim vector
  # para: x         samples, n*p matrix
  # para: beta      learning rate
  # value: h.hat    bandwidth selected, a p dim vector
  
  p <- dim(samples)[2]
  n <- dim(samples)[1]
  h.hat <- rep(h.init, p)
  
  tmpfun <- function(ii)  # for Z.i
    ((xx[jj] - samples[ii, jj])^2 - h.hat[jj]^2) * dmvnorm(xx, mean=samples[ii,], sigma=diag(h.hat))
  
  A <- 1:p
  while(length(A) > 0){
    # loop for each variable in set A
    for (jj in A) {
      # jj   idx for dims
      # ii   idx for samples
      Z.i <- unlist(base::lapply(1:n, FUN=tmpfun))
      Z <- mean(Z.i) /  h.hat[jj]^3 / prod(h.hat) / (2*pi)^(p/2)
      s <- var(Z.i) / h.hat[jj]^6 / (prod(h.hat))^2 / (2*pi)^(p)
      lam <- sqrt(2*s*log(n*cn)) / 30
      if (abs(Z) > lam) {
        h.hat[jj] <- h.hat[jj] * beta
      } else {
        A <- A[A != jj]
      }
    }
  }
  return(h.hat)
}

rodeo.local <- function(t, samples){
  # estimate target points t
  # para: t   target points, a matrix, each row is a point
  # para: x   data points, a matrix, each row is a point
  
  p <- dim(samples)[2]
  n <- dim(samples)[1]
  m <- dim(t)[1]
  
  # h.hat <- t(apply(t, MARGIN=1, FUN=rodeo.local.bw, x=x))   # this is a matrix, num of row is length of t
  # here I prefer not using parallel loop
  snowfall::sfInit(parallel=TRUE, cpus=50)
  snowfall::sfLibrary(stats)
  snowfall::sfLibrary(mvtnorm)
  snowfall::sfExport("n", "p", "samples")
  h.hat <- t(snowfall::sfApply(x=t, margin=1, fun=rodeo.local.bw, samples=samples))   # this is a matrix, num of row is length of t
  snowfall::sfStop()

  f.hat.t <- function(ii){
    # estimate at a single point xx, h is corresponding h.hat
    xx <- t[ii, ]
    h <- h.hat[ii, ]
    mean(unlist(lapply(X=1:n, FUN=function(ii) mvtnorm::dmvnorm(xx, mean=samples[ii,], sigma=diag(h)))))
  }
  
  # f.hat <- apply(X=t, MARGIN=1, FUN=f.hat.x)
  # here I prefer not using parallel loop
  snowfall::sfInit(parallel=TRUE, cpus=50)
  snowfall::sfLibrary(stats)
  snowfall::sfLibrary(mvtnorm)
  snowfall::sfExport("n", "p", "samples", "t", "h.hat")
  f.hat <- unlist(snowfall::sfLapply(x=1:m, fun=f.hat.t))
  snowfall::sfStop()
  
  return(list(f.hat=f.hat,h.hat=h.hat))
}

```


```{r, echo=FALSE, warning=FALSE}
# using Rodeo to estimate f(t)

a.para <- 0.025
# square region
tmp.mesh <- plot3D::mesh(seq(0, 1, a.para), seq(0, 1, a.para))
xx <- tmp.mesh$x
yy <- tmp.mesh$y
t1 <- matrix(xx, ncol=1)
t2 <- matrix(yy, ncol=1)
t <- cbind(t1, t2)

# # estimate
# suppressWarnings(res <- rodeo.local(t, samples))
res <- rodeo.local2(t, samples)
fit.rodeo <- res$f.hat
h.hat <- res$h.hat

# draw figure
library(plot3D)
zz <- matrix(fit.rodeo, nrow=nrow(xx), byrow=TRUE)
surf3D(x=xx, y=yy, z=zz, xlab="relevant variable", ylab="irrelevant variable", zlab="Density", main="Rodeo", bty = "f", colkey = FALSE, colvar=matrix(rep(1, length(zz)), nrow(zz)), border = "black", theta=90)

hh1 <- matrix(h.hat[,1], nrow=nrow(xx), byrow=TRUE)
surf3D(x=xx, y=yy, z=hh1, xlab="relevant variable", ylab="irrelevant variable", zlab="Density", main="Bandwidth", bty = "f", colkey = FALSE, colvar=matrix(rep(1, length(zz)), nrow(zz)), border = "black")

hh2 <- matrix(h.hat[,2], nrow=nrow(xx), byrow=TRUE)
surf3D(x=xx, y=yy, z=hh2, xlab="relevant variable", ylab="irrelevant variable", zlab="Density", main="Bandwidth", bty = "f", colkey = FALSE, colvar=matrix(rep(1, length(zz)), nrow(zz)), border = "black")
```

just estimate a single line at x2 = 0.5

```{r, echo=FALSE, warning=FALSE}
# just estimate a single line at x2 = 0.5
a.para <- 0.025
tmp.mesh <- plot3D::mesh(seq(0, 1, a.para), c(0.5))   # irrelevent variable is constant
xx <- tmp.mesh$x
yy <- tmp.mesh$y
t1 <- matrix(xx, ncol=1)
t2 <- matrix(yy, ncol=1)
t <- cbind(t1, t2)

# # estimate
res <- rodeo.local2(t, samples)
fit.rodeo <- res$f.hat
h.hat <- res$h.hat

plot(xx, fit.rodeo, "l", main="Rodeo", ylab="Density", ylim=c(0, 2))
lines(y, z, lty=1, lwd=2)
plot(xx, h.hat[,1], "l", main="Bandwidth", ylab="h of r.var.")
plot(xx, h.hat[,2], "l", main="Bandwidth", ylab="h of irr.var.")

```

Just using x1 to estimate, rodeo

```{r}
# 1-dim situation true density
pro <- c(2/3, 1/3)
shape1 <- c(1, 10)
shape2 <- c(2, 10)
y <- seq(0, 1, 0.01)
z <- rep(0, length(y))
for (ii in 1:2) {
  z <- z + pro[ii] * dbeta(y, shape1[ii], shape2[ii])
}

# using rodeo for 1-dim to estimate relative variable
rodeo.local.bw1 <- function(xx, x, h.init=1.3/log(log(n)), beta=0.95, cn=log(n)/n){
  # bandwidth selection
  # para: xx        target point at which we want to estimate f(x)
  # para: x         samples
  # para: beta      learning rate
  # value: h.init   bandwidth
  h1 <- h.init
  while(TRUE){
    Z.i <- ((xx - x)^2 - h1^2) * exp(- (xx - x)^2 / h1^2 / 2) / h1^4 / sqrt(2*pi)
    Z <- mean(Z.i) 
    s <- var(Z.i)
    lam <- sqrt(2*s*log(n*cn)) / 30
    if (abs(Z) > lam) {
      h1 <- h1 * beta
    } else {
      return(h1)
    }
  }
}
a.para <- 0.001
t <- seq(0, 1, a.para)
h <- unlist(base::lapply(X=t, FUN=rodeo.local.bw1, x=x1, h.init=0.4/log(log(length(x1)))))
plot(t, h, "l", main="Bandwidth of Rodeo", xlab="x", ylab="h")
fit.rodeo <- rodeo.local1(t=t, x=x1)
plot(t, fit.rodeo, "l", lty=2, ylim=c(0,2.5), xlim=c(0, 1), main="Rodeo", xlab="x", ylab="Density")
lines(y, z, lty=1, lwd=2)
legend("topright", legend=c("True Density", "Rodeo"), col=1, lty=c(1, 2), lwd=c(2, 1))

# KDE
library(MASS)   # unbiased cross-validation to select the bandwidth of a Gaussian kernel density estimator
h.opt <- MASS::ucv(x1, nb=1000, lower=0.1)
cat("The optimal bandwidth given by unbiased cv is: ", h.opt)
fit.density <- stats::density(x1, kernel="gaussian", bw=h.opt)
plot(fit.density, "l", lty=2, main="KDE with U-CV", ylab="Denstiy", ylim=c(0,2.5), xlim=c(0, 1), xlab="x")
lines(y, z, lty=1, lwd=1)

# hist
hist(x1, freq=FALSE, breaks=30)
lines(y, z, lty=1, lwd=1)
```
### Geyser data