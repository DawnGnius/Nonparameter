\section{Introduction}

\subsection{Motivation}

Modern data acquisition routinely produces massive amounts of high dimensional and highly complex datasets, including interactive logs from search engines, traffic records from network routing, chip data from high throughput genomic experiments, and image data from functional Magnetic Resonance Imaging (fMRI). 
Driven by the complexity of these new types of data, highly adaptive and reliable data analysis procedures are crucially needed. 

Older high dimensional theories and learning algorithms rely heavily on parametric models, which assume the data come from an underlying distribution that can be characterized by a finite number of parameters. 
If these assumptions are correct, orcal property -- accurate estimates, precise preditcions and consistent variable selections \citep{fan2010selective} -- can be expected. 
However, given the increasing complexity of modern data, conclusions inferred under these restrictive assumptions can be misleading. 
To handle this challenge, we focus on nonparametric methods, which directly conduct inference in infinite-dimensional spaces and thus are powerful enough to capture the subtleties in most modern applications.